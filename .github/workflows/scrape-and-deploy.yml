name: Scrape NHK Easy News and Deploy to GitHub Pages

on:
  # Run daily at 9 PM JST (12:00 UTC) - articles typically published 19:30-20:45 JST
  schedule:
    - cron: "0 12 * * *"

  # Allow manual triggering
  workflow_dispatch:

  # Run on pushes to main branch for testing
  push:
    branches: [main]

permissions:
  contents: read
  pages: write
  id-token: write

# Allow only one concurrent deployment
concurrency:
  group: "pages"
  cancel-in-progress: false

jobs:
  scrape-and-build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.12"

      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: "latest"

      - name: Create virtual environment and install dependencies
        run: |
          uv sync

      - name: Install Playwright browsers
        run: |
          uv run python -m playwright install --with-deps firefox

      - name: Create data directory
        run: mkdir -p data

      - name: Run scraper and site generator
        run: |
          uv run python src/main.py

      - name: Setup Pages
        uses: actions/configure-pages@v5

      - name: Upload to GitHub Pages
        uses: actions/upload-pages-artifact@v3
        with:
          path: docs

  deploy:
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    runs-on: ubuntu-latest
    needs: scrape-and-build

    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
